{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e938ecf9-7551-40bc-b7c1-5ab461dcb3c5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n╔═════════════════════════════════════════════════════════════════════════════╗\n║                                                                             ║\n║                    \uD83E\uDD47 SEC SMART MONEY - GOLD LAYER                         ║\n║                                                                             ║\n║        Creating analytical views and business intelligence layer             ║\n║                                                                             ║\n╚═════════════════════════════════════════════════════════════════════════════╝\n\n\n\uD83D\uDCCB EXECUTION PARAMETERS:\n  Catalog Name:          fintech_analytics\n  Silver Schema:         fintech_analytics.silver\n  Gold Schema:           fintech_analytics.gold\n  Environment:           prod\n  Minimum Conviction:    50\n  Lookback Days:         365\n  Lookback Start:        2025-02-22\n  Run Date:              2026-02-22\n\n"
     ]
    }
   ],
   "source": [
    "# COMMAND ----------\n",
    "# ===================================================================\n",
    "# SEC SMART MONEY - GOLD LAYER\n",
    "# Production-Grade Analytics & Aggregations (VIEWS)\n",
    "# ===================================================================\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "import traceback\n",
    "\n",
    "print(\"\"\"\n",
    "╔═════════════════════════════════════════════════════════════════════════════╗\n",
    "║                                                                             ║\n",
    "║                    \uD83E\uDD47 SEC SMART MONEY - GOLD LAYER                         ║\n",
    "║                                                                             ║\n",
    "║        Creating analytical views and business intelligence layer             ║\n",
    "║                                                                             ║\n",
    "╚═════════════════════════════════════════════════════════════════════════════╝\n",
    "\"\"\")\n",
    "\n",
    "# COMMAND ----------\n",
    "# ===================================================================\n",
    "# PARAMETERS - Production Configuration\n",
    "# ===================================================================\n",
    "\n",
    "# Define parameters with clear labels\n",
    "dbutils.widgets.text(\n",
    "    \"catalog_name\",\n",
    "    \"fintech_analytics\",\n",
    "    \"1. Catalog Name\"\n",
    ")\n",
    "\n",
    "dbutils.widgets.dropdown(\n",
    "    \"environment\",\n",
    "    \"prod\",\n",
    "    [\"dev\", \"staging\", \"prod\"],\n",
    "    \"2. Environment\"\n",
    ")\n",
    "\n",
    "dbutils.widgets.text(\n",
    "    \"min_conviction_score\",\n",
    "    \"50\",\n",
    "    \"3. Minimum Conviction Score\"\n",
    ")\n",
    "\n",
    "dbutils.widgets.text(\n",
    "    \"lookback_days\",\n",
    "    \"365\",\n",
    "    \"4. Lookback Days\"\n",
    ")\n",
    "\n",
    "# COMMAND ----------\n",
    "# ===================================================================\n",
    "# GET PARAMETER VALUES - Safe Retrieval Pattern\n",
    "# ===================================================================\n",
    "\n",
    "try:\n",
    "    catalog_name = dbutils.widgets.get(\"catalog_name\")\n",
    "    if not catalog_name:\n",
    "        catalog_name = \"fintech_analytics\"\n",
    "except:\n",
    "    catalog_name = \"fintech_analytics\"\n",
    "\n",
    "try:\n",
    "    environment = dbutils.widgets.get(\"environment\")\n",
    "    if not environment:\n",
    "        environment = \"prod\"\n",
    "except:\n",
    "    environment = \"prod\"\n",
    "\n",
    "try:\n",
    "    min_conviction = int(dbutils.widgets.get(\"min_conviction_score\"))\n",
    "    if min_conviction < 0:\n",
    "        min_conviction = 50\n",
    "except:\n",
    "    min_conviction = 50\n",
    "\n",
    "try:\n",
    "    lookback_days = int(dbutils.widgets.get(\"lookback_days\"))\n",
    "    if lookback_days <= 0:\n",
    "        lookback_days = 365\n",
    "except:\n",
    "    lookback_days = 365\n",
    "\n",
    "# Construct schemas\n",
    "silver_schema = f\"{catalog_name}.silver\"\n",
    "gold_schema = f\"{catalog_name}.gold\"\n",
    "\n",
    "# Calculate dates\n",
    "run_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "lookback_start = (datetime.now() - timedelta(days=lookback_days)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Print configuration\n",
    "print(f\"\"\"\n",
    "\uD83D\uDCCB EXECUTION PARAMETERS:\n",
    "  Catalog Name:          {catalog_name}\n",
    "  Silver Schema:         {silver_schema}\n",
    "  Gold Schema:           {gold_schema}\n",
    "  Environment:           {environment}\n",
    "  Minimum Conviction:    {min_conviction}\n",
    "  Lookback Days:         {lookback_days}\n",
    "  Lookback Start:        {lookback_start}\n",
    "  Run Date:              {run_date}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "880b8dac-5e32-42eb-8d34-a861ebf27083",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n================================================================================\nSTEP 1: Verifying Silver Layer\n================================================================================\n✅ Silver layer verified: 394 rows available\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# STEP 1: Verify Silver Layer Exists\n",
    "# ===================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 1: Verifying Silver Layer\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "try:\n",
    "    silver_count = spark.sql(f\"\"\"\n",
    "    SELECT COUNT(*) as count\n",
    "    FROM {silver_schema}.silver_fact_insider_transactions\n",
    "    \"\"\").collect()[0]['count']\n",
    "    \n",
    "    print(f\"✅ Silver layer verified: {silver_count:,} rows available\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error accessing silver layer: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1a1667c7-3a9c-4406-8a59-a7d70bf91012",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n================================================================================\nSTEP 2: Creating Gold Views\n================================================================================\n\n\uD83D\uDCCA Creating VIEW: gold_insider_summary_by_company\n    ✅ Created VIEW: 26 company records\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# STEP 2: CREATE GOLD VIEWS\n",
    "# ===================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 2: Creating Gold Views\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# COMMAND ----------\n",
    "# VIEW 1: gold_insider_summary_by_company\n",
    "# Summarizes insider activity by company\n",
    "\n",
    "try:\n",
    "    print(\"\\n\uD83D\uDCCA Creating VIEW: gold_insider_summary_by_company\")\n",
    "    \n",
    "    spark.sql(f\"\"\"\n",
    "    CREATE OR REPLACE VIEW {gold_schema}.gold_insider_summary_by_company AS\n",
    "    SELECT \n",
    "        company_name,\n",
    "        COUNT(DISTINCT insider_name) as num_insiders,\n",
    "        COUNT(*) as total_transactions,\n",
    "        SUM(CASE WHEN acquired_disposed = 'A' THEN 1 ELSE 0 END) as total_buys,\n",
    "        SUM(CASE WHEN acquired_disposed = 'D' THEN 1 ELSE 0 END) as total_sells,\n",
    "        ROUND(AVG(CAST(confidence_score AS DOUBLE)), 2) as avg_confidence,\n",
    "        MAX(filing_date) as latest_filing_date\n",
    "    FROM {silver_schema}.silver_fact_insider_transactions\n",
    "    WHERE confidence_score >= {min_conviction}\n",
    "        AND filing_date >= '{lookback_start}'\n",
    "    GROUP BY company_name\n",
    "    ORDER BY total_transactions DESC\n",
    "    \"\"\")\n",
    "    \n",
    "    view_count = spark.sql(f\"SELECT COUNT(*) as count FROM {gold_schema}.gold_insider_summary_by_company\").collect()[0]['count']\n",
    "    print(f\"    ✅ Created VIEW: {view_count:,} company records\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"    ❌ Error creating view: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bdfbf8a1-bbdd-41b1-9b42-bcd39eddb6a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n\uD83D\uDCCA Creating VIEW: gold_high_activity_insiders\n    ✅ Created VIEW: 2 insider records\n"
     ]
    }
   ],
   "source": [
    "# COMMAND ----------\n",
    "# VIEW 2: gold_high_activity_insiders\n",
    "# Identifies insiders with high transaction activity\n",
    "\n",
    "try:\n",
    "    print(\"\\n\uD83D\uDCCA Creating VIEW: gold_high_activity_insiders\")\n",
    "    \n",
    "    spark.sql(f\"\"\"\n",
    "    CREATE OR REPLACE VIEW {gold_schema}.gold_high_activity_insiders AS\n",
    "    SELECT \n",
    "        insider_name,\n",
    "        COUNT(DISTINCT company_name) as num_companies,\n",
    "        COUNT(*) as total_transactions,\n",
    "        ROUND(AVG(CAST(confidence_score AS DOUBLE)), 2) as avg_confidence,\n",
    "        MAX(filing_date) as latest_transaction\n",
    "    FROM {silver_schema}.silver_fact_insider_transactions\n",
    "    WHERE confidence_score >= {min_conviction}\n",
    "        AND filing_date >= '{lookback_start}'\n",
    "    GROUP BY insider_name\n",
    "    HAVING COUNT(*) >= 5\n",
    "    ORDER BY total_transactions DESC\n",
    "    \"\"\")\n",
    "    \n",
    "    insider_count = spark.sql(f\"SELECT COUNT(*) as count FROM {gold_schema}.gold_high_activity_insiders\").collect()[0]['count']\n",
    "    print(f\"    ✅ Created VIEW: {insider_count:,} insider records\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"    ❌ Error creating view: {str(e)}\")\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "152bf9a9-f600-4c5d-bb45-254ec7d5c50c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n\uD83D\uDCCA Creating VIEW: gold_combined_smart_money\n    ✅ Created VIEW: 357 signal records\n"
     ]
    }
   ],
   "source": [
    "# VIEW 3: gold_combined_smart_money\n",
    "# Combined view for smart money signals\n",
    "\n",
    "try:\n",
    "    print(\"\\n\uD83D\uDCCA Creating VIEW: gold_combined_smart_money\")\n",
    "    \n",
    "    spark.sql(f\"\"\"\n",
    "    CREATE OR REPLACE VIEW {gold_schema}.gold_combined_smart_money AS\n",
    "    SELECT \n",
    "        t.company_name,\n",
    "        t.insider_name,\n",
    "        t.filing_date,\n",
    "        t.transaction_date,\n",
    "        t.acquired_disposed,\n",
    "        t.shares,\n",
    "        t.price_per_share,\n",
    "        ROUND(CAST(t.shares AS DOUBLE) * CAST(t.price_per_share AS DOUBLE), 2) as transaction_value,\n",
    "        t.confidence_score,\n",
    "        CASE \n",
    "            WHEN CAST(t.confidence_score AS DOUBLE) >= 80 THEN 'STRONG'\n",
    "            WHEN CAST(t.confidence_score AS DOUBLE) >= 60 THEN 'MODERATE'\n",
    "            ELSE 'WEAK'\n",
    "        END as signal_strength\n",
    "    FROM {silver_schema}.silver_fact_insider_transactions t\n",
    "    WHERE CAST(t.confidence_score AS DOUBLE) >= {min_conviction}\n",
    "        AND t.filing_date >= '{lookback_start}'\n",
    "    ORDER BY CAST(t.confidence_score AS DOUBLE) DESC, t.filing_date DESC\n",
    "    \"\"\")\n",
    "    \n",
    "    signal_count = spark.sql(f\"SELECT COUNT(*) as count FROM {gold_schema}.gold_combined_smart_money\").collect()[0]['count']\n",
    "    print(f\"    ✅ Created VIEW: {signal_count:,} signal records\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"    ❌ Error creating view: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b2ce7994-0a78-4040-975f-8a454cadfddc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n\uD83D\uDCCA Creating VIEW: gold_insider_sentiment\n    ✅ Created VIEW: 89 sentiment records\n"
     ]
    }
   ],
   "source": [
    "# COMMAND ----------\n",
    "# VIEW 4: gold_insider_sentiment\n",
    "# Sentiment analysis by company and date\n",
    "\n",
    "try:\n",
    "    print(\"\\n\uD83D\uDCCA Creating VIEW: gold_insider_sentiment\")\n",
    "    \n",
    "    spark.sql(f\"\"\"\n",
    "    CREATE OR REPLACE VIEW {gold_schema}.gold_insider_sentiment AS\n",
    "    SELECT \n",
    "        company_name,\n",
    "        filing_date,\n",
    "        SUM(CASE WHEN acquired_disposed = 'A' THEN 1 ELSE 0 END) as buy_count,\n",
    "        SUM(CASE WHEN acquired_disposed = 'D' THEN 1 ELSE 0 END) as sell_count,\n",
    "        COUNT(*) as total_transactions,\n",
    "        ROUND(\n",
    "            100.0 * SUM(CASE WHEN acquired_disposed = 'A' THEN 1 ELSE 0 END) / COUNT(*), \n",
    "            2\n",
    "        ) as buy_percentage,\n",
    "        ROUND(AVG(CAST(confidence_score AS DOUBLE)), 2) as avg_confidence,\n",
    "        CASE \n",
    "            WHEN SUM(CASE WHEN acquired_disposed = 'A' THEN 1 ELSE 0 END) > \n",
    "                 SUM(CASE WHEN acquired_disposed = 'D' THEN 1 ELSE 0 END) \n",
    "            THEN 'BULLISH'\n",
    "            WHEN SUM(CASE WHEN acquired_disposed = 'A' THEN 1 ELSE 0 END) < \n",
    "                 SUM(CASE WHEN acquired_disposed = 'D' THEN 1 ELSE 0 END) \n",
    "            THEN 'BEARISH'\n",
    "            ELSE 'NEUTRAL'\n",
    "        END as sentiment\n",
    "    FROM {silver_schema}.silver_fact_insider_transactions\n",
    "    WHERE confidence_score >= {min_conviction}\n",
    "        AND filing_date >= '{lookback_start}'\n",
    "    GROUP BY company_name, filing_date\n",
    "    ORDER BY filing_date DESC, company_name\n",
    "    \"\"\")\n",
    "    \n",
    "    sentiment_count = spark.sql(f\"SELECT COUNT(*) as count FROM {gold_schema}.gold_insider_sentiment\").collect()[0]['count']\n",
    "    print(f\"    ✅ Created VIEW: {sentiment_count:,} sentiment records\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"    ❌ Error creating view: {str(e)}\")\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a0312c5b-5056-49f1-a444-4211ff66aa16",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n\uD83D\uDCCA Creating VIEW: gold_institutional_conviction\n    ✅ Created VIEW: 55 conviction records\n"
     ]
    }
   ],
   "source": [
    "# VIEW 5: gold_institutional_conviction\n",
    "# Conviction scores by institution and company\n",
    "\n",
    "try:\n",
    "    print(\"\\n\uD83D\uDCCA Creating VIEW: gold_institutional_conviction\")\n",
    "    \n",
    "    spark.sql(f\"\"\"\n",
    "    CREATE OR REPLACE VIEW {gold_schema}.gold_institutional_conviction AS\n",
    "    SELECT \n",
    "        company_name,\n",
    "        security_title,\n",
    "        COUNT(*) as transaction_count,\n",
    "        ROUND(AVG(CAST(confidence_score AS DOUBLE)), 2) as avg_conviction_score,\n",
    "        MAX(CAST(confidence_score AS DOUBLE)) as max_conviction_score,\n",
    "        MIN(CAST(confidence_score AS DOUBLE)) as min_conviction_score,\n",
    "        MAX(filing_date) as latest_date,\n",
    "        ROUND(\n",
    "            (MAX(CAST(confidence_score AS DOUBLE)) - MIN(CAST(confidence_score AS DOUBLE))) \n",
    "            / NULLIF(MAX(CAST(confidence_score AS DOUBLE)), 0) * 100, \n",
    "            2\n",
    "        ) as conviction_volatility\n",
    "    FROM {silver_schema}.silver_fact_insider_transactions\n",
    "    WHERE confidence_score >= {min_conviction}\n",
    "        AND filing_date >= '{lookback_start}'\n",
    "    GROUP BY company_name, security_title\n",
    "    ORDER BY avg_conviction_score DESC\n",
    "    \"\"\")\n",
    "    \n",
    "    conviction_count = spark.sql(f\"SELECT COUNT(*) as count FROM {gold_schema}.gold_institutional_conviction\").collect()[0]['count']\n",
    "    print(f\"    ✅ Created VIEW: {conviction_count:,} conviction records\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"    ❌ Error creating view: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3579760e-38f1-454e-8cae-ef2462f91bb2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n\uD83D\uDCCA Creating VIEW: gold_kpi_summary\n    ✅ Created VIEW: 4 KPI records\n"
     ]
    }
   ],
   "source": [
    "# VIEW 6: gold_kpi_summary\n",
    "# Key performance indicators\n",
    "\n",
    "try:\n",
    "    print(\"\\n\uD83D\uDCCA Creating VIEW: gold_kpi_summary\")\n",
    "    \n",
    "    spark.sql(f\"\"\"\n",
    "    CREATE OR REPLACE VIEW {gold_schema}.gold_kpi_summary AS\n",
    "    SELECT \n",
    "        '{run_date}' as metric_date,\n",
    "        'Total Transactions' as metric_name,\n",
    "        CAST(COUNT(*) AS STRING) as metric_value,\n",
    "        '{environment}' as environment\n",
    "    FROM {silver_schema}.silver_fact_insider_transactions\n",
    "    WHERE confidence_score >= {min_conviction}\n",
    "        AND filing_date >= '{lookback_start}'\n",
    "    \n",
    "    UNION ALL\n",
    "    \n",
    "    SELECT \n",
    "        '{run_date}' as metric_date,\n",
    "        'Total Companies' as metric_name,\n",
    "        CAST(COUNT(DISTINCT company_name) AS STRING) as metric_value,\n",
    "        '{environment}' as environment\n",
    "    FROM {silver_schema}.silver_fact_insider_transactions\n",
    "    WHERE confidence_score >= {min_conviction}\n",
    "        AND filing_date >= '{lookback_start}'\n",
    "    \n",
    "    UNION ALL\n",
    "    \n",
    "    SELECT \n",
    "        '{run_date}' as metric_date,\n",
    "        'Total Insiders' as metric_name,\n",
    "        CAST(COUNT(DISTINCT insider_name) AS STRING) as metric_value,\n",
    "        '{environment}' as environment\n",
    "    FROM {silver_schema}.silver_fact_insider_transactions\n",
    "    WHERE confidence_score >= {min_conviction}\n",
    "        AND filing_date >= '{lookback_start}'\n",
    "    \n",
    "    UNION ALL\n",
    "    \n",
    "    SELECT \n",
    "        '{run_date}' as metric_date,\n",
    "        'Avg Confidence Score' as metric_name,\n",
    "        CAST(ROUND(AVG(CAST(confidence_score AS DOUBLE)), 2) AS STRING) as metric_value,\n",
    "        '{environment}' as environment\n",
    "    FROM {silver_schema}.silver_fact_insider_transactions\n",
    "    WHERE confidence_score >= {min_conviction}\n",
    "        AND filing_date >= '{lookback_start}'\n",
    "    \"\"\")\n",
    "    \n",
    "    kpi_count = spark.sql(f\"SELECT COUNT(*) as count FROM {gold_schema}.gold_kpi_summary\").collect()[0]['count']\n",
    "    print(f\"    ✅ Created VIEW: {kpi_count:,} KPI records\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"    ❌ Error creating view: {str(e)}\")\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "18fe954f-9be2-48c3-b8ff-614c112ca3a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n\uD83D\uDCCA Creating VIEW: gold_smart_money_signals\n    ✅ Created VIEW: 357 signal records\n"
     ]
    }
   ],
   "source": [
    "# VIEW 7: gold_smart_money_signals\n",
    "# Smart money buy/sell signals\n",
    "\n",
    "try:\n",
    "    print(\"\\n\uD83D\uDCCA Creating VIEW: gold_smart_money_signals\")\n",
    "    \n",
    "    spark.sql(f\"\"\"\n",
    "    CREATE OR REPLACE VIEW {gold_schema}.gold_smart_money_signals AS\n",
    "    SELECT \n",
    "        company_name,\n",
    "        insider_name,\n",
    "        filing_date as signal_date,\n",
    "        transaction_date,\n",
    "        CASE WHEN acquired_disposed = 'A' THEN 'BUY' WHEN acquired_disposed = 'D' THEN 'SELL' ELSE NULL END as signal_type,\n",
    "        shares,\n",
    "        price_per_share,\n",
    "        ROUND(CAST(shares AS DOUBLE) * CAST(price_per_share AS DOUBLE), 2) as transaction_value,\n",
    "        confidence_score,\n",
    "        CASE \n",
    "            WHEN CAST(confidence_score AS DOUBLE) >= 80 THEN 'STRONG'\n",
    "            WHEN CAST(confidence_score AS DOUBLE) >= 60 THEN 'MODERATE'\n",
    "            ELSE 'WEAK'\n",
    "        END as signal_strength,\n",
    "        security_title\n",
    "    FROM {silver_schema}.silver_fact_insider_transactions\n",
    "    WHERE CAST(confidence_score AS DOUBLE) >= {min_conviction}\n",
    "        AND filing_date >= '{lookback_start}'\n",
    "    ORDER BY CAST(confidence_score AS DOUBLE) DESC, filing_date DESC\n",
    "    \"\"\")\n",
    "    \n",
    "    signals_count = spark.sql(f\"SELECT COUNT(*) as count FROM {gold_schema}.gold_smart_money_signals\").collect()[0]['count']\n",
    "    print(f\"    ✅ Created VIEW: {signals_count:,} signal records\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"    ❌ Error creating view: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "66ca95df-dd57-4dc5-957b-21ba435d946e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n\uD83D\uDCCA Creating VIEW: gold_top_holdings_by_institution\n    ✅ Created VIEW: 257 holding records\n"
     ]
    }
   ],
   "source": [
    "# VIEW 8: gold_top_holdings_by_institution\n",
    "# Top holdings analysis\n",
    "\n",
    "try:\n",
    "    print(\"\\n\uD83D\uDCCA Creating VIEW: gold_top_holdings_by_institution\")\n",
    "    \n",
    "    spark.sql(f\"\"\"\n",
    "    CREATE OR REPLACE VIEW {gold_schema}.gold_top_holdings_by_institution AS\n",
    "    SELECT \n",
    "        company_name,\n",
    "        insider_name,\n",
    "        security_title,\n",
    "        COUNT(*) as holding_count,\n",
    "        SUM(CAST(shares AS BIGINT)) as total_shares,\n",
    "        ROUND(AVG(CAST(price_per_share AS DOUBLE)), 2) as avg_price,\n",
    "        MAX(filing_date) as latest_update,\n",
    "        ROUND(AVG(CAST(confidence_score AS DOUBLE)), 2) as avg_confidence\n",
    "    FROM {silver_schema}.silver_fact_insider_transactions\n",
    "    WHERE confidence_score >= {min_conviction}\n",
    "        AND filing_date >= '{lookback_start}'\n",
    "    GROUP BY company_name, insider_name, security_title\n",
    "    \"\"\")\n",
    "    \n",
    "    holdings_count = spark.sql(f\"SELECT COUNT(*) as count FROM {gold_schema}.gold_top_holdings_by_institution\").collect()[0]['count']\n",
    "    print(f\"    ✅ Created VIEW: {holdings_count:,} holding records\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"    ❌ Error creating view: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "458d8b96-b358-43f5-b439-84b7094b723e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n================================================================================\n\uD83C\uDF89 GOLD LAYER VIEWS CREATED SUCCESSFULLY\n================================================================================\n\nSummary:\n  ✅ gold_insider_summary_by_company\n  ✅ gold_high_activity_insiders\n  ✅ gold_combined_smart_money\n  ✅ gold_insider_sentiment\n  ✅ gold_institutional_conviction\n  ✅ gold_kpi_summary\n  ✅ gold_smart_money_signals\n  ✅ gold_top_holdings_by_institution\n  \n  Environment: prod\n  Run date: 2026-02-22\n  All views created as logical views (not physical tables)\n\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# STEP 3: Summary & Completion\n",
    "# ===================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"\uD83C\uDF89 GOLD LAYER VIEWS CREATED SUCCESSFULLY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\"\"\n",
    "Summary:\n",
    "  ✅ gold_insider_summary_by_company\n",
    "  ✅ gold_high_activity_insiders\n",
    "  ✅ gold_combined_smart_money\n",
    "  ✅ gold_insider_sentiment\n",
    "  ✅ gold_institutional_conviction\n",
    "  ✅ gold_kpi_summary\n",
    "  ✅ gold_smart_money_signals\n",
    "  ✅ gold_top_holdings_by_institution\n",
    "  \n",
    "  Environment: {environment}\n",
    "  Run date: {run_date}\n",
    "  All views created as logical views (not physical tables)\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d4a3bee6-c321-4a80-997b-0bf4037fde64",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n✅ Gold layer ready for dashboards and reporting!\")\n",
    "\n",
    "# Return success\n",
    "dbutils.notebook.exit(\"SUCCESS\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5278571850869733,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "sec_smart_money_gold",
   "widgets": {
    "catalog_name": {
     "currentValue": "fintech_analytics",
     "nuid": "531edfac-b537-430e-9b39-bb46d6d8d33b",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "fintech_analytics",
      "label": "1. Catalog Name",
      "name": "catalog_name",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "fintech_analytics",
      "label": "1. Catalog Name",
      "name": "catalog_name",
      "options": {
       "widgetType": "text",
       "autoCreated": false,
       "validationRegex": null
      }
     }
    },
    "environment": {
     "currentValue": "prod",
     "nuid": "5b07bf45-01c0-49b7-b77b-8b853d0cd869",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "prod",
      "label": "2. Environment",
      "name": "environment",
      "options": {
       "widgetDisplayType": "Dropdown",
       "choices": [
        "dev",
        "staging",
        "prod"
       ],
       "fixedDomain": true,
       "multiselect": false
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "dropdown",
      "defaultValue": "prod",
      "label": "2. Environment",
      "name": "environment",
      "options": {
       "widgetType": "dropdown",
       "autoCreated": false,
       "choices": [
        "dev",
        "staging",
        "prod"
       ]
      }
     }
    },
    "lookback_days": {
     "currentValue": "365",
     "nuid": "f92547f1-9026-4672-a3d9-f66f360e84f5",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "365",
      "label": "4. Lookback Days",
      "name": "lookback_days",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "365",
      "label": "4. Lookback Days",
      "name": "lookback_days",
      "options": {
       "widgetType": "text",
       "autoCreated": false,
       "validationRegex": null
      }
     }
    },
    "min_conviction_score": {
     "currentValue": "50",
     "nuid": "587852c6-efec-45cd-9dd2-ecf6bcd09266",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "50",
      "label": "3. Minimum Conviction Score",
      "name": "min_conviction_score",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "50",
      "label": "3. Minimum Conviction Score",
      "name": "min_conviction_score",
      "options": {
       "widgetType": "text",
       "autoCreated": false,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}